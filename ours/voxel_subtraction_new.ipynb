{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'descartes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3ba36cdfd8b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutilities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRotationTranslationData\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutilities\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mglob\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\OverfittedHackathon\\ours\\utilities\\math_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshapely\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maffinity\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mshapely\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepared\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprep\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdescartes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPolygonPatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'descartes'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from utilities.math_utils import RotationTranslationData\n",
    "from utilities import data_utils\n",
    "from glob import glob\n",
    "import pickle\n",
    "\n",
    "from time import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_grid_and_hash(df, voxel_size):\n",
    "    \"\"\" \n",
    "    add grid and hash to each point of a given point cloud\n",
    "    \"\"\"\n",
    "    df_grid = df.iloc[:,:3]//voxel_size\n",
    "    df_grid.iloc[:, :3] = df_grid.iloc[:, :3]*voxel_size + voxel_size//2\n",
    "    df_grid['voxel_id'] = df_grid.apply(lambda x: hash((x[0], x[1], x[2])), axis=1)\n",
    "    df_grid = pd.concat([df, df_grid], axis=1)\n",
    "    df_grid.columns = ['x', 'y', 'z', 'r', 'x_grid', 'y_grid', 'z_grid', 'voxel_id']\n",
    "    return df_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"E:/Datasets/DataHack/World2/Train/vid_1/\"\n",
    "pickles_path = \"voxelling_output/\"\n",
    "n_frames_per_side=10\n",
    "shift=5\n",
    "voxel_size=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob(base_dir+\"/*point*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = base_dir.split(\"/\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list_dfs_voxel_scene(base_dir, voxel_size, upto=None):\n",
    "    global all_files\n",
    "    list_df_voxel_scene = []\n",
    "#     all_files = glob(base_dir+\"/*point*\")\n",
    "    if upto is not None:\n",
    "        all_files = all_files[:upto]\n",
    "    \n",
    "    for f in tqdm(all_files):\n",
    "        list_df_voxel_scene.append( add_grid_and_hash(pd.read_csv(f, header=None), voxel_size))\n",
    "    list_df_voxel_scene = pd.Series(list_df_voxel_scene).values\n",
    "    return list_df_voxel_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_file = pickles_path+\"list_df_voxel_scene__%s__voxel_size_%d.p\"%(vid, voxel_size)\n",
    "\n",
    "if os.path.exists(list_df_file):\n",
    "    list_df_voxel_scene = pickle.load(open(list_df_file, \"rb\"))\n",
    "else:\n",
    "    list_df_voxel_scene = create_list_dfs_voxel_scene(base_dir, voxel_size, upto=None)\n",
    "    pickle.dump(list_df_voxel_scene, open(pickles_path+\"list_df_voxel_scene__%s__voxel_size_%d.p\"%(vid, voxel_size), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_idx_for_frame(frame_idx, n_frames_per_side, shift):\n",
    "    list_idx = np.array(list(np.arange(frame_idx-shift-n_frames_per_side,frame_idx-shift)) + list(np.arange(frame_idx+shift+1,frame_idx+shift+n_frames_per_side+1)))\n",
    "    return list_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scene_voxel_df(list_df_voxel_scene, list_idx):\n",
    "    list_df_voxel_scene_for_frame = list_df_voxel_scene[list_idx]\n",
    "    df_scene = pd.concat(list_df_voxel_scene_for_frame).drop_duplicates(\"voxel_id\")\n",
    "    return df_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_voxel_subtracted_frame(list_df_voxel_scene, frame_idx, n_frames_per_side, shift):\n",
    "    \n",
    "    list_idx = get_list_idx_for_frame(frame_idx, n_frames_per_side, shift)\n",
    "    \n",
    "    df_voxel_scene = create_scene_voxel_df(list_df_voxel_scene, list_idx)\n",
    "    df_voxel_frame = create_scene_voxel_df(list_df_voxel_scene, [frame_idx])\n",
    "\n",
    "    df_subtracted_frame = df_voxel_frame[~df_voxel_frame.voxel_id.isin(df_voxel_scene.voxel_id)]\n",
    "    return df_subtracted_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_to_voxel(ser, voxel_size):\n",
    "    # ser: [x, y, z, r]\n",
    "    ser_out = ser.iloc[:3]//voxel_size\n",
    "    ser_out = ser_out*voxel_size + voxel_size//2\n",
    "    voxel_id = hash((ser_out[0], ser_out[1], ser_out[2]))\n",
    "    \n",
    "#     return pd.Series(ser_out.tolist()+[voxel_id])\n",
    "    return voxel_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_frame_for_movie(frame, folder, all_files, frame_idx):\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "    filename = os.path.basename(all_files[frame_idx])\n",
    "    frame.to_csv(folder + filename, header=None, index=False)\n",
    "    labels_filename = filename.replace('pointcloud', 'labels')\n",
    "    pd.DataFrame([0]*frame.shape[0]).to_csv(folder + labels_filename, header=None, index=False)\n",
    "\n",
    "    egomotion_filename = filename.replace('pointcloud', 'egomotion')\n",
    "    pd.DataFrame([0.]*6).T.to_csv(folder + egomotion_filename, header=None, index=False)\n",
    "    print('frame {} saved successfuly'.format(frame_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame_idx=15\n",
    "# todo: add skips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_idx = get_list_idx_for_frame(frame_idx, n_frames_per_side, shift)\n",
    "# list_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_subtracted_frame = get_df_voxel_subtracted_frame(list_df_voxel_scene, frame_idx, n_frames_per_side, shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_subtracted_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_frame_orig = pd.read_csv(all_files[frame_idx], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df_frame_orig[\"voxel_id\"] =  df_frame_orig.apply(lambda x: point_to_voxel(x, voxel_size), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_frame_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_labels = df_frame_orig.voxel_id.isin(df_subtracted_frame.voxel_id)\n",
    "# df_labels.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_frame_orig_subtracted = df_frame_orig[df_labels]\n",
    "# df_labels = df_labels.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_frame_orig_subtracted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_frame_orig_subtracted = df_frame_orig_subtracted.iloc[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # \n",
    "# save_frame_for_movie(df_frame_orig_subtracted, \"tmp_only_labeled/\", all_files, frame_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame_idx=15\n",
    "for frame_idx in tqdm(range(31,900)):\n",
    "    print(\"=========================================================================\")\n",
    "    print(\"frame_idx = %d\"%frame_idx)\n",
    "    print(\"=========================================================================\")\n",
    "\n",
    "    tic = time()\n",
    "    list_idx = get_list_idx_for_frame(frame_idx, n_frames_per_side, shift)\n",
    "    toc = time(); print(toc-tic, \": list_idx = get_list_idx_for_frame(frame_idx, n_frames_per_side, shift)\"); tic=time()\n",
    "    \n",
    "    df_subtracted_frame = get_df_voxel_subtracted_frame(list_df_voxel_scene, frame_idx, n_frames_per_side, shift)\n",
    "    toc = time(); print(toc-tic, \": df_subtracted_frame = get_df_voxel_subtracted_frame(list_df_voxel_scene, frame_idx, n_frames_per_side, shift)\"); tic=time()\n",
    "    \n",
    "    df_frame_orig = pd.read_csv(all_files[frame_idx], header=None)\n",
    "#     df_frame_orig[\"voxel_id\"] =  df_frame_orig.apply(lambda x: point_to_voxel(x, voxel_size), axis=1)\n",
    "    df_frame_orig[\"voxel_id\"] =  ((df_frame_orig.iloc[:, :3]//voxel_size)*voxel_size + voxel_size//2).apply(lambda x: hash((x[0], x[1], x[2])), axis=1)\n",
    "    toc = time(); print(toc-tic, \": df_frame_orig['voxel_id'] =  df_frame_orig.apply(lambda x: point_to_voxel(x, voxel_size), axis=1)\"); tic=time()\n",
    "    \n",
    "    df_labels = df_frame_orig.voxel_id.isin(df_subtracted_frame.voxel_id)\n",
    "    toc = time(); print(toc-tic, \": df_labels = df_frame_orig.voxel_id.isin(df_subtracted_frame.voxel_id)\"); tic=time()\n",
    "    \n",
    "    df_frame_orig_subtracted = df_frame_orig[df_labels]\n",
    "    toc = time(); print(toc-tic, \": df_frame_orig_subtracted = df_frame_orig[df_labels]\"); tic=time()\n",
    "    \n",
    "    print(df_frame_orig_subtracted.shape)\n",
    "    df_labels = df_labels.astype(int)\n",
    "    file_labels = \"voxelling_output/submission_files/vid_1_pred/\" + os.path.basename(all_files[frame_idx]).replace(\"pointcloud\", \"labels\")\n",
    "    print(\"file_labels:\", file_labels)\n",
    "    df_labels.to_csv(file_labels, header=None, index=False)\n",
    "    toc = time(); print(toc-tic, ': df_labels.to_csv(pickles_path+\"df_labels__frame_%d__%s__voxel_size_%d.p\"%(frame_idx, vid, voxel_size))'); tic=time()\n",
    "    \n",
    "    print(df_labels.sum())\n",
    "    df_frame_orig_subtracted = df_frame_orig_subtracted.iloc[:, :4]\n",
    "    df_frame_orig_subtracted.to_csv(pickles_path+\"df_frame_orig_subtracted__frame_%d__%s__voxel_size_%d.csv\"%(frame_idx, vid, voxel_size), header=None, index=False)\n",
    "    save_frame_for_movie(df_frame_orig_subtracted, \"tmp_only_labeled/\", all_files, frame_idx)\n",
    "    toc = time(); print(toc-tic, ': save_frame_for_movie(df_frame_orig_subtracted, \"tmp_only_labeled/\", all_files, frame_idx)'); tic=time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir = \"E:/Datasets/DataHack/Train\"\n",
    "# for sub_dir in os.listdir(base_dir):\n",
    "#     print(sub_dir)\n",
    "# #     for f in glob(sub_dir+\"/*point*\"):\n",
    "# #     df = add_grid_and_hash(pd.read_csv(f), header=None), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cars:\n",
    "len(list_idx)\n",
    "# list_df_voxel_scene[list_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for road distant lines:\n",
    "df_frame_orig_subtracted.columns = list(\"xyzr\")\n",
    "df_frame_orig_subtracted.plot(kind=\"scatter\", x=\"x\", y=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pc_to_grid(df, voxel_size, dest_dir, dest_name):\n",
    "#     # df_frame points are in world coordinate system\n",
    "#     # dest_name may be frame number\n",
    "#     start_time = time()\n",
    "# #     df = pd.read_csv(csv_path, header=None)\n",
    "\n",
    "#     df_xyz = df.iloc[:,:3]\n",
    "#     ref_ser = df.iloc[:, 3]\n",
    "#     df_grid = df_xyz//voxel_size\n",
    "#     df_grid[3] = ref_ser\n",
    "#     df_grid.columns=list(\"xyzr\")\n",
    "#     df_voxel = df_grid.groupby(['x','y','z']).apply(lambda x: x.iloc[:, 3].mean()).to_frame()\n",
    "#     df_voxel.reset_index(drop=False, inplace=True)\n",
    "#     df_voxel.iloc[:, :3] = df_voxel.iloc[:, :3]*voxel_size + voxel_size//2\n",
    "#     df_voxel= df_voxel.astype(np.int)\n",
    "#     base_name = os.path.join(dest_dir, dest_name)\n",
    "#     df_voxel.to_csv(base_name + '_pointcloud.csv', header=None, index=False)\n",
    "#     pd.DataFrame([0]*df_voxel.shape[0]).to_csv(base_name+'_labels.csv', header=None, index=False)\n",
    "#     pd.DataFrame([0.]*6).T.to_csv(base_name+'_egomotion.csv', header=None, index=False)\n",
    "#     print('single file runtime: {}'.format(time()-start_time))\n",
    "    \n",
    "#     return df_voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# world_dir = \"E:/Datasets/DataHack/World/Train/vid_1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scene_frames = glob(world_dir+\"/*point*\")[:10] + glob(world_dir+\"/*point*\")[20:30]\n",
    "# cur_frame = glob(world_dir+\"/*point*\")[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_pcs = []\n",
    "# for f in scene_frames:\n",
    "#     s_pcs.append(pd.read_csv(f, header=None))\n",
    "# df_scene_pcs = pd.concat(s_pcs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# try:\n",
    "#     os.mkdir(\"tmp/\")\n",
    "# except:\n",
    "#     pass\n",
    "# pc_to_grid(df_scene_pcs, 20, \"tmp\", \"0000000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df_cur_pc = pd.read_csv(cur_frame, header=None)\n",
    "# pc_to_grid(df_cur_pc, 20, \"tmp\", \"0000001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = pd.read_csv(\"tmp/0000000_pointcloud.csv\", header=None)\n",
    "# c = pd.read_csv(\"tmp/0000001_pointcloud.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w['voxel_id'] = w.apply(lambda x: hash((x[0], x[1], x[2])), axis=1)\n",
    "# c['voxel_id'] = c.apply(lambda x: hash((x[0], x[1], x[2])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_out = c[~c.voxel_id.isin(w.voxel_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c.shape, c_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_out = c_out.iloc[:, :4]\n",
    "# c_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     os.mkdir(\"tmp_out/\")\n",
    "# except:\n",
    "#     pass\n",
    "# pc_to_grid(c_out, 20, \"tmp_out\", \"0000002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_df_voxels = []\n",
    "# for f in g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def voxel_classification_for_frame(vid_dir, frame_idx):\n",
    "#     df_pc_scene = ...\n",
    "#     df_pc_frame = ...\n",
    "#     df_voxel_scene = build_voxel(df_pc_scene)\n",
    "#     df_voxel_frame = build_voxel()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datahack",
   "language": "python",
   "name": "datahack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
