{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from utilities.math_utils import RotationTranslationData\n",
    "from utilities import data_utils\n",
    "from glob import glob\n",
    "import pickle\n",
    "\n",
    "from time import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Params and Paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_n_frames_per_side=100\n",
    "const_shift=150\n",
    "\n",
    "rot_n_frames_per_side=8\n",
    "rot_shift=5\n",
    "\n",
    "voxel_size=20\n",
    "voting_scene_frac_to_drop = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"C:/Users\\shlomi\\Documents\\Work\\OverfittedHackathon\\ours/voxelling_output\\Test_world_2/vid_42/\"\n",
    "pickles_path = \"voxelling_output/\"\n",
    "orig_files_path = \"C:/Users\\shlomi\\Documents\\Work\\OverfittedHackathon/ours/voxelling_output/Test/vid_42/\"\n",
    "labels_path = \"voxelling_output/submission_files/test_vid_42_pred__final/\"\n",
    "# labels_path = \"voxelling_output/submission_files/checks/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_grid_and_hash(df, voxel_size):\n",
    "    \"\"\" \n",
    "    add grid and hash to each point of a given point cloud\n",
    "    \"\"\"\n",
    "    df_grid = df.iloc[:,:3]//voxel_size\n",
    "    df_grid.iloc[:, :3] = df_grid.iloc[:, :3]*voxel_size + voxel_size//2\n",
    "    df_grid['voxel_id'] = df_grid.apply(lambda x: hash((x[0], x[1], x[2])), axis=1)\n",
    "    df_grid = pd.concat([df, df_grid], axis=1)\n",
    "    df_grid.columns = ['x', 'y', 'z', 'r', 'x_grid', 'y_grid', 'z_grid', 'voxel_id']\n",
    "    return df_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob(base_dir+\"/*point*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = base_dir.split(\"/\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list_dfs_voxel_scene(base_dir, voxel_size, upto=None):\n",
    "    global all_files\n",
    "    list_df_voxel_scene = []\n",
    "#     all_files = glob(base_dir+\"/*point*\")\n",
    "    if upto is not None:\n",
    "        all_files = all_files[:upto]\n",
    "    \n",
    "    for f in tqdm(all_files):\n",
    "        list_df_voxel_scene.append( add_grid_and_hash(pd.read_csv(f, header=None), voxel_size))\n",
    "    list_df_voxel_scene = pd.Series(list_df_voxel_scene).values\n",
    "    return list_df_voxel_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_file = pickles_path+\"list_df_voxel_scene__%s__voxel_size_%d.p\"%(vid, voxel_size)\n",
    "\n",
    "if os.path.exists(list_df_file):\n",
    "    list_df_voxel_scene = pickle.load(open(list_df_file, \"rb\"))\n",
    "else:\n",
    "    list_df_voxel_scene = create_list_dfs_voxel_scene(base_dir, voxel_size, upto=None)\n",
    "    pickle.dump(list_df_voxel_scene, open(pickles_path+\"list_df_voxel_scene__%s__voxel_size_%d.p\"%(vid, voxel_size), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_idx_for_frame(frame_idx, n_frames_per_side, shift):\n",
    "    list_idx = np.array(list(np.arange(frame_idx-shift-n_frames_per_side,frame_idx-shift)) + list(np.arange(frame_idx+shift+1,frame_idx+shift+n_frames_per_side+1)))\n",
    "    list_idx = [i for i in list_idx if i>=0 and i<=list_df_voxel_scene.shape[0]]\n",
    "    return list_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scene_voxel_df(list_df_voxel_scene, list_idx, frac_to_drop=0.5):\n",
    "#     print(list_idx)\n",
    "    list_df_voxel_scene_for_frame = list_df_voxel_scene[list_idx]\n",
    "    df_scene = pd.concat(list_df_voxel_scene_for_frame)#.drop_duplicates(\"voxel_id\")\n",
    "#     print(df_scene)\n",
    "#     df_scene.keys()\n",
    "#     df_scene.groupby([\"x_grid\", \"y_grid\", \"z_grid\"]).value_counts()\n",
    "    dfff = df_scene.groupby([\"x_grid\", \"y_grid\", \"z_grid\"]).apply(len).reset_index(drop=False)\n",
    "\n",
    "    dfff = dfff[dfff[0]>frac_to_drop*len(list_idx)]\n",
    "    dfff[\"v_index\"] = dfff.iloc[:, :3].apply(lambda x: hash((x.iloc[0], x.iloc[1], x.iloc[2])), axis=1)\n",
    "#     print(df_scene.shape)\n",
    "    df_scene.drop_duplicates([\"x_grid\", \"y_grid\", \"z_grid\"], inplace=True)\n",
    "#     print(df_scene.shape)\n",
    "    df_scene = df_scene[df_scene.voxel_id.isin(dfff.v_index)]\n",
    "#     print(df_scene.shape)\n",
    "    \n",
    "    return df_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_voxel_subtracted_frame(list_df_voxel_scene, frame_idx, n_frames_per_side, shift):\n",
    "    \n",
    "    list_idx_uf = get_list_idx_for_frame(frame_idx, n_frames_per_side, shift)\n",
    "#     print ('--get_df_voxel_sub--\\nlist idx_uf: {}\\nlist_idx   :{}\\n-------'.format(list_idx_uf, list_idx))\n",
    "    df_voxel_scene = create_scene_voxel_df(list_df_voxel_scene, list_idx, frac_to_drop=voting_scene_frac_to_drop)\n",
    "    df_voxel_frame = create_scene_voxel_df(list_df_voxel_scene, [frame_idx])\n",
    "\n",
    "    df_subtracted_frame = df_voxel_frame[~df_voxel_frame.voxel_id.isin(df_voxel_scene.voxel_id)]\n",
    "    return df_subtracted_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_to_voxel(ser, voxel_size):\n",
    "    # ser: [x, y, z, r]\n",
    "    ser_out = ser.iloc[:3]//voxel_size\n",
    "    ser_out = ser_out*voxel_size + voxel_size//2\n",
    "    voxel_id = hash((ser_out[0], ser_out[1], ser_out[2]))\n",
    "    \n",
    "#     return pd.Series(ser_out.tolist()+[voxel_id])\n",
    "    return voxel_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_frame_for_movie(frame, folder, all_files, frame_idx):\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "    filename = os.path.basename(all_files[frame_idx])\n",
    "    frame.to_csv(folder + filename, header=None, index=False)\n",
    "    labels_filename = filename.replace('pointcloud', 'labels')\n",
    "    pd.DataFrame([0]*frame.shape[0]).to_csv(folder + labels_filename, header=None, index=False)\n",
    "\n",
    "    egomotion_filename = filename.replace('pointcloud', 'egomotion')\n",
    "    pd.DataFrame([0.]*6).T.to_csv(folder + egomotion_filename, header=None, index=False)\n",
    "    print('frame {} saved successfuly'.format(frame_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_distant_lines(frame_idx, df_labels, orig_files_path):\n",
    "    filename = (7-len(str(frame_idx)))*\"0\"+str(frame_idx)+\"_pointcloud.csv\"\n",
    "    dff = pd.read_csv(orig_files_path+filename, header=None)\n",
    "    dff.columns = list(\"xyzr\")\n",
    "    dff[\"l\"] = df_labels.tolist()\n",
    "    dff = dff[dff.l==1]\n",
    "#     print(dff.shape)\n",
    "#     dff.head() \n",
    "\n",
    "#     dff = dff[dff.x>dff.x.min()+(dff.x.max()-dff.x.min())*0.2]\n",
    "#     print(dff.shape)\n",
    "#     dff.head()\n",
    "    \n",
    "    dff = dff[dff.z<dff.z.min()+(dff.z.max()-dff.z.min())*0.3]\n",
    "#     print(dff.shape)\n",
    "#     dff.head()\n",
    "\n",
    "    dff = dff[(dff[\"r\"]>5)&(dff[\"r\"]<15)]\n",
    "#     print(dff.shape)\n",
    "#     dff.head()\n",
    "\n",
    "    df_labels.loc[dff.index] = False\n",
    "    return df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_distant_points(frame_idx, df_labels, orig_files_path):\n",
    "    filename = (7-len(str(frame_idx)))*\"0\"+str(frame_idx)+\"_pointcloud.csv\"\n",
    "    dff = pd.read_csv(orig_files_path+filename, header=None)\n",
    "    dff.columns = list(\"xyzr\")\n",
    "    dff[\"l\"] = df_labels.tolist()\n",
    "    dff = dff[dff.l==1]\n",
    "#     print(dff.shape)\n",
    "#     dff.head() \n",
    "#     print(dff.describe())\n",
    "    dff = dff[dff[\"x\"]>5500]\n",
    "#     print(dff.describe())\n",
    "#     rr = np.sqrt(dff.x**2+dff.y**2)\n",
    "#     dff = dff[rr<10]\n",
    "#     print(dff.shape)\n",
    "#     dff.head()\n",
    "    \n",
    "#     dff = dff[dff.z<dff.z.min()+(dff.z.max()-dff.z.min())*0.3]\n",
    "#     print(dff.shape)\n",
    "#     dff.head()\n",
    "\n",
    "#     dff = dff[(dff[\"r\"]>5)&(dff[\"r\"]<15)]\n",
    "#     print(dff.shape)\n",
    "#     dff.head()\n",
    "\n",
    "    df_labels.loc[dff.index] = False\n",
    "    return df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_high_theta_points(frame_idx, df_labels, orig_files_path):\n",
    "    filename = (7-len(str(frame_idx)))*\"0\"+str(frame_idx)+\"_pointcloud.csv\"\n",
    "    dff = pd.read_csv(orig_files_path+filename, header=None)\n",
    "    dff.columns = list(\"xyzr\")\n",
    "    dff[\"l\"] = df_labels.tolist()\n",
    "    dff = dff[dff.l==1]\n",
    "#     print(dff.shape)\n",
    "#     dff.head() \n",
    "\n",
    "    theta = np.abs(np.arctan(dff.y/dff.x))\n",
    "    dff = dff[theta>0.9*theta.max()]\n",
    "    dff = dff[dff.x>300]\n",
    "#     print(dff.shape)\n",
    "#     dff.head()\n",
    "    \n",
    "#     dff = dff[dff.z<dff.z.min()+(dff.z.max()-dff.z.min())*0.3]\n",
    "#     print(dff.shape)\n",
    "#     dff.head()\n",
    "\n",
    "#     dff = dff[(dff[\"r\"]>5)&(dff[\"r\"]<15)]\n",
    "#     print(dff.shape)\n",
    "#     dff.head()\n",
    "\n",
    "    df_labels.loc[dff.index] = False\n",
    "    return df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_close_lines(frame_idx, df_labels, orig_files_path):\n",
    "    filename = (7-len(str(frame_idx)))*\"0\"+str(frame_idx)+\"_pointcloud.csv\"\n",
    "    dff = pd.read_csv(orig_files_path+filename, header=None)\n",
    "    dff.columns = list(\"xyzr\")\n",
    "    dff[\"l\"] = df_labels.tolist()\n",
    "    dff = dff[dff.l==1]\n",
    "#     print(dff.shape)\n",
    "#     dff.head() \n",
    "\n",
    "    dff = dff[dff.x<dff.x.min()+(dff.x.max()-dff.x.min())*0.1]\n",
    "#     print(dff.shape)\n",
    "#     dff.head()\n",
    "    \n",
    "    dff = dff[dff.z<dff.z.min()+(dff.z.max()-dff.z.min())*0.01]\n",
    "#     print(dff.shape)\n",
    "#     dff.head()\n",
    "\n",
    "#     dff = dff[(dff[\"r\"]>5)&(dff[\"r\"]<15)]\n",
    "# #     print(dff.shape)\n",
    "# #     dff.head()\n",
    "\n",
    "    df_labels.loc[dff.index] = False\n",
    "    return df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_high_points(frame_idx, df_labels, orig_files_path):\n",
    "    filename = (7-len(str(frame_idx)))*\"0\"+str(frame_idx)+\"_pointcloud.csv\"\n",
    "    dff = pd.read_csv(orig_files_path+filename, header=None)\n",
    "    dff.columns = list(\"xyzr\")\n",
    "    dff[\"l\"] = df_labels.tolist()\n",
    "    dff = dff[dff.l==1]\n",
    "#     print(dff.shape)\n",
    "#     dff.head() \n",
    "\n",
    "#     dff = dff[dff.x<dff.x.min()+(dff.x.max()-dff.x.min())*0.15]\n",
    "#     print(dff.shape)\n",
    "#     dff.head()\n",
    "    \n",
    "    dff = dff[dff.z>400]\n",
    "    print(dff.shape)\n",
    "    dff.head()\n",
    "\n",
    "#     dff = dff[(dff[\"r\"]>5)&(dff[\"r\"]<15)]\n",
    "# #     print(dff.shape)\n",
    "# #     dff.head()\n",
    "\n",
    "    df_labels.loc[dff.index] = False\n",
    "    return df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_low_points(frame_idx, df_labels, orig_files_path):\n",
    "    filename = (7-len(str(frame_idx)))*\"0\"+str(frame_idx)+\"_pointcloud.csv\"\n",
    "    dff = pd.read_csv(orig_files_path+filename, header=None)\n",
    "    dff.columns = list(\"xyzr\")\n",
    "    dff[\"l\"] = df_labels.tolist()\n",
    "    dff = dff[dff.l==1]\n",
    "#     print(dff.shape)\n",
    "#     dff.head() \n",
    "\n",
    "#     dff = dff[dff.x<dff.x.min()+(dff.x.max()-dff.x.min())*0.15]\n",
    "#     print(dff.shape)\n",
    "#     dff.head()\n",
    "#     print(\"\\n\\nXMIN:\", dff.x.min())\n",
    "    dff = dff[dff.z<dff.z.min()+15]\n",
    "    print(dff.shape)\n",
    "    dff.head()\n",
    "\n",
    "#     dff = dff[(dff[\"r\"]>5)&(dff[\"r\"]<15)]\n",
    "# #     print(dff.shape)\n",
    "# #     dff.head()\n",
    "\n",
    "    df_labels.loc[dff.index] = False\n",
    "    return df_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame_idx=15\n",
    "frames_range = range(1000)\n",
    "# frames_range = range(15,900)\n",
    "for frame_idx in tqdm(frames_range):\n",
    "    print(\"=========================================================================\")\n",
    "    print(\"frame_idx = %d\"%frame_idx)\n",
    "    print(\"=========================================================================\")\n",
    "\n",
    "    tic = time()\n",
    "    \n",
    "    shift = const_shift\n",
    "    n_frames_per_side = const_n_frames_per_side\n",
    "    \n",
    "    list_idx_uf = get_list_idx_for_frame(frame_idx, n_frames_per_side, shift)\n",
    "    list_idx = [i for i in list_idx_uf if i>=0 and i<=list_df_voxel_scene.shape[0]-1]\n",
    "#     print ('--main--\\nlist idx_uf: {}\\nlist_idx   :{}\\n-------'.format(list_idx_uf, list_idx))\n",
    "    toc = time(); print(toc-tic, \": list_idx = get_list_idx_for_frame(frame_idx, n_frames_per_side, shift)\"); tic=time()\n",
    "    \n",
    "    df_scene = create_scene_voxel_df(list_df_voxel_scene, list_idx)\n",
    "    \n",
    "    \n",
    "#     if frame_idx%frames_per_scene==0 :\n",
    "    df_subtracted_frame = get_df_voxel_subtracted_frame(list_df_voxel_scene, frame_idx, n_frames_per_side, shift)\n",
    "    toc = time(); print(toc-tic, \": df_subtracted_frame = get_df_voxel_subtracted_frame(list_df_voxel_scene, frame_idx, n_frames_per_side, shift)\"); tic=time()\n",
    "    \n",
    "    df_frame_orig = pd.read_csv(all_files[frame_idx], header=None)\n",
    "#     df_frame_orig[\"voxel_id\"] =  df_frame_orig.apply(lambda x: point_to_voxel(x, voxel_size), axis=1)\n",
    "    df_frame_orig[\"voxel_id\"] =  ((df_frame_orig.iloc[:, :3]//voxel_size)*voxel_size + voxel_size//2).apply(lambda x: hash((x[0], x[1], x[2])), axis=1)\n",
    "    toc = time(); print(toc-tic, \": df_frame_orig['voxel_id'] =  df_frame_orig.apply(lambda x: point_to_voxel(x, voxel_size), axis=1)\"); tic=time()\n",
    "    \n",
    "    df_labels = df_frame_orig.voxel_id.isin(df_subtracted_frame.voxel_id)\n",
    "    toc = time(); print(toc-tic, \": df_labels = df_frame_orig.voxel_id.isin(df_subtracted_frame.voxel_id)\"); tic=time()\n",
    "    \n",
    "    if (df_labels.sum()/df_labels.shape[0])>0.5:\n",
    "        print(\"\\nIN ROTATION MODE! fraction of green pixels before:\", (df_labels.sum()/df_labels.shape[0]))\n",
    "        n_frames_per_side=rot_n_frames_per_side\n",
    "        shift=rot_shift\n",
    "        \n",
    "        list_idx_uf = get_list_idx_for_frame(frame_idx, n_frames_per_side, shift)\n",
    "        list_idx = [i for i in list_idx_uf if i>=0 and i<=list_df_voxel_scene.shape[0]-1]\n",
    "        print(\"\\nIN ROTATION MODE: list_idx:\", list_idx)\n",
    "    #     print ('--main--\\nlist idx_uf: {}\\nlist_idx   :{}\\n-------'.format(list_idx_uf, list_idx))\n",
    "        toc = time(); print(toc-tic, \": list_idx = get_list_idx_for_frame(frame_idx, n_frames_per_side, shift)\"); tic=time()\n",
    "\n",
    "        df_scene = create_scene_voxel_df(list_df_voxel_scene, list_idx)\n",
    "\n",
    "\n",
    "    #     if frame_idx%frames_per_scene==0 :\n",
    "        df_subtracted_frame = get_df_voxel_subtracted_frame(list_df_voxel_scene, frame_idx, n_frames_per_side, shift)\n",
    "        toc = time(); print(toc-tic, \": df_subtracted_frame = get_df_voxel_subtracted_frame(list_df_voxel_scene, frame_idx, n_frames_per_side, shift)\"); tic=time()\n",
    "\n",
    "        df_frame_orig = pd.read_csv(all_files[frame_idx], header=None)\n",
    "    #     df_frame_orig[\"voxel_id\"] =  df_frame_orig.apply(lambda x: point_to_voxel(x, voxel_size), axis=1)\n",
    "        df_frame_orig[\"voxel_id\"] =  ((df_frame_orig.iloc[:, :3]//voxel_size)*voxel_size + voxel_size//2).apply(lambda x: hash((x[0], x[1], x[2])), axis=1)\n",
    "        toc = time(); print(toc-tic, \": df_frame_orig['voxel_id'] =  df_frame_orig.apply(lambda x: point_to_voxel(x, voxel_size), axis=1)\"); tic=time()\n",
    "\n",
    "        df_labels = df_frame_orig.voxel_id.isin(df_subtracted_frame.voxel_id)\n",
    "        toc = time(); print(toc-tic, \": df_labels = df_frame_orig.voxel_id.isin(df_subtracted_frame.voxel_id)\"); tic=time()\n",
    "\n",
    "        print(\"\\nIN ROTATION MODE! fraction of green pixels after:\", (df_labels.sum()/df_labels.shape[0]))\n",
    "        \n",
    "    \n",
    "    \n",
    "    # filters\n",
    "    df_labels = remove_distant_lines(frame_idx, df_labels, orig_files_path)\n",
    "    df_labels = remove_distant_points(frame_idx, df_labels, orig_files_path)\n",
    "    df_labels = remove_close_lines(frame_idx, df_labels, orig_files_path)\n",
    "    df_labels = remove_high_points(frame_idx, df_labels, orig_files_path)\n",
    "    df_labels = remove_low_points(frame_idx, df_labels, orig_files_path)\n",
    "    df_labels = remove_high_theta_points(frame_idx, df_labels, orig_files_path)\n",
    "    \n",
    "#     df_labels.iloc[:] = False\n",
    "    \n",
    "    df_frame_orig_subtracted = df_frame_orig[df_labels]\n",
    "    toc = time(); print(toc-tic, \": df_frame_orig_subtracted = df_frame_orig[df_labels]\"); tic=time()\n",
    "    \n",
    "    print(df_frame_orig_subtracted.shape)\n",
    "    df_labels = df_labels.astype(int)\n",
    "    file_labels = labels_path + os.path.basename(all_files[frame_idx]).replace(\"pointcloud\", \"labels\")\n",
    "    print(\"file_labels:\", file_labels)\n",
    "    df_labels.to_csv(file_labels, header=None, index=False)\n",
    "    toc = time(); print(toc-tic, ': df_labels.to_csv(pickles_path+\"df_labels__frame_%d__%s__voxel_size_%d_(%d,%d,%d).p\"%(frame_idx, vid, voxel_size, n_frames_per_side, shift, n_frames_per_side))'); tic=time()\n",
    "    \n",
    "    print(df_labels.sum())\n",
    "    df_frame_orig_subtracted = df_frame_orig_subtracted.iloc[:, :4]\n",
    "#     df_frame_orig_subtracted.to_csv(pickles_path+\"df_frame_orig_subtracted__frame_%d__%s__voxel_size%d_(%d,%d,%d).p\"%(frame_idx, vid, voxel_size, n_frames_per_side, shift, n_frames_per_side)), header=None, index=False)\n",
    "#     save_frame_for_movie(df_frame_orig_subtracted, \"tmp_only_labeled/\", all_files, frame_idx)\n",
    "    toc = time(); print(toc-tic, ': save_frame_for_movie(df_frame_orig_subtracted, \"tmp_only_labeled/\", all_files, frame_idx)'); tic=time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataHack",
   "language": "python",
   "name": "datahack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
